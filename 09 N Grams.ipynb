{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67f4630c-d1f2-4ff9-a7e9-fa5302cc3b83",
   "metadata": {},
   "source": [
    "# N-Gram Language Modelling with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea82d6f-8ace-47d2-b4ac-25e9404c6706",
   "metadata": {},
   "source": [
    "- Similar concept of BOW\n",
    "- We have to provide gram range when we create vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab5be01-363a-4c35-be4c-a09cbfa3bcec",
   "metadata": {},
   "source": [
    "<img src='ngram.jfif' width=\"800\" height=\"600\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ad731b1-f042-4eb0-afab-871d60367048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai' 'field' 'helps' 'improve' 'is' 'learning' 'machine' 'models' 'nlp'\n",
      " 'of']\n",
      "\n",
      "\n",
      "[[1 1 0 0 1 0 0 0 1 1]\n",
      " [0 0 1 1 0 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# same code of BOW\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample texts\n",
    "documents = [\n",
    "    \"NLP is a field of AI.\",\n",
    "    \"Machine learning helps NLP models improve.\"\n",
    "]\n",
    "\n",
    "# Create BoW model for bi gram\n",
    "vectorizer = CountVectorizer() #uni gram\n",
    "# In CountVectorizer,  pass parameter : ngram_range\n",
    "# (2,2) = bigram\n",
    "# (3,3) = tri gram\n",
    "# (4,4) = quad gram\n",
    "\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and show vocabulary\n",
    "print(vectorizer.get_feature_names_out())  \n",
    "print(\"\\n\")\n",
    "print(X.toarray())  # BoW matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd6357a0-e0d3-4b88-9b15-c0f3470f72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['helps nlp models improve' 'is field of ai' 'learning helps nlp models'\n",
      " 'machine learning helps nlp' 'nlp is field of']\n",
      "\n",
      "\n",
      "[[0 1 0 0 1]\n",
      " [1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create BoW model for quad gram\n",
    "vectorizer = CountVectorizer(ngram_range=(4,4))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and show vocabulary\n",
    "print(len(vectorizer.get_feature_names_out())) \n",
    "print(vectorizer.get_feature_names_out())  \n",
    "print(\"\\n\")\n",
    "print(X.toarray())  # BoW matrix representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7d523-9c0e-4e35-a9f6-d5796ec45fc5",
   "metadata": {},
   "source": [
    "#### Special case\n",
    "- If we pass ngram_range=(1,2) then it will consider unigram and bigram both.\n",
    "- ngram_range=(2,3) means it will consider bigram and trigram both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8df4375d-946f-433c-9188-4738f17c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "['field of' 'field of ai' 'helps nlp' 'helps nlp models' 'is field'\n",
      " 'is field of' 'learning helps' 'learning helps nlp' 'machine learning'\n",
      " 'machine learning helps' 'models improve' 'nlp is' 'nlp is field'\n",
      " 'nlp models' 'nlp models improve' 'of ai']\n",
      "\n",
      "\n",
      "[[1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 1]\n",
      " [0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create BoW model for range(2,3)\n",
    "vectorizer = CountVectorizer(ngram_range=(2,3))\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and show vocabulary\n",
    "print(len(vectorizer.get_feature_names_out()))  \n",
    "print(vectorizer.get_feature_names_out()) \n",
    "print(\"\\n\")\n",
    "print(X.toarray())  # BoW matrix representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ba59e-9284-4d36-a3d3-2011c88732b8",
   "metadata": {},
   "source": [
    "### Benefits\n",
    "- capture semantic of the sentence\n",
    "- easy to understand\n",
    "\n",
    "### Disadvantage\n",
    "- for largae datasets, dimentionality of vocabulary will increase\n",
    "- increase time complexity ,slows down the algorithm\n",
    "- some time new sentence can be ignores due to not matching words with bag of words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
